{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Loading the NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to extract features from a single text document\n",
    "def extract_features(text,filename):\n",
    "    features = {}\n",
    "    text = re.sub(r\"Take notes.*?-- Sign up today.*?\\.\", \"\", text, flags=re.DOTALL).strip()\n",
    "    \n",
    "    # 1. Extract Date of Judgment\n",
    "    date_match = re.search(r'\\b\\d{1,2} [A-Z][a-z]+, \\d{4}\\b', text)\n",
    "    if date_match:\n",
    "        features['Date of Judgment'] = date_match.group()\n",
    "    \n",
    "    #2\n",
    "    case_title_match = re.search(r\"^.*?Supreme Court of India\\n(.*?) on\", text)\n",
    "    features['case_title'] = case_title_match.group(1).strip() if case_title_match else None\n",
    "\n",
    "    author_match = re.search(r\"Author:\\s*(.*?)\\n\", text)\n",
    "    features['author'] = author_match.group(1).strip() if author_match else None\n",
    "\n",
    "    # 3. Extract Court Name\n",
    "    court_match = re.search(r'\\b(Supreme Court of India|High Court of \\w+|District Court)\\b', text)\n",
    "    if court_match:\n",
    "        features['Court Name'] = court_match.group()\n",
    "    \n",
    "    # 4. Jurisdiction Level\n",
    "    if \"Supreme Court\" in text:\n",
    "        features['Jurisdiction Level'] = \"Appellate\"\n",
    "    elif \"High Court\" in text:\n",
    "        features['Jurisdiction Level'] = \"Appellate or Original\"\n",
    "    else:\n",
    "        features['Jurisdiction Level'] = \"Trial\"\n",
    "    \n",
    "    # 5. Geographical Region\n",
    "    state_match = None\n",
    "    if \"High Court\" in text:\n",
    "        state_match = re.search(r'\\b(\\w+) High Court\\b', text)\n",
    "    if state_match:\n",
    "        features['Geographical Region'] = state_match.group(1)\n",
    "    else:\n",
    "        features['Geographical Region'] = \"India\"\n",
    "\n",
    "    # 6. Case Type\n",
    "    if \"CIVIL\" in text or \"Civil Appeal\" in text:\n",
    "        features['Case Type'] = \"Civil Appeal\"\n",
    "    elif \"CRIMINAL\" in text:\n",
    "        features['Case Type'] = \"Criminal\"\n",
    "    \n",
    "    # 7. Legal Area\n",
    "    def extract_legal_area(text):\n",
    "        legal_areas = {\n",
    "            \"Motor Accident Claim\": r\"Motor Vehicles Act|Motor Accident\",\n",
    "            \"Property Dispute\": r\"Transfer of Property Act|Land Acquisition Act\",\n",
    "            \"Family Law\": r\"Hindu Marriage Act|Divorce|Custody|Alimony|Maintenance\",\n",
    "            \"Contract Law\": r\"Indian Contract Act|Breach of Contract\",\n",
    "            \"Labour Law\": r\"Industrial Disputes Act|Labour Welfare|Employment Dispute\",\n",
    "            \"Intellectual Property\": r\"Copyright Act|Trademark Act|Patent Act|IPR\",\n",
    "            \"Tax Law\": r\"Income Tax Act|GST Act|Wealth Tax|Direct Tax\",\n",
    "            \"Criminal Law\": r\"Indian Penal Code|Criminal Procedure Code|IPC|CrPC\",\n",
    "            \"Constitutional Law\": r\"Constitution of India|Fundamental Rights|Writ Petition\",\n",
    "            \"Environmental Law\": r\"Environment Protection Act|Wildlife Protection Act|Pollution Control\",\n",
    "            # Add more legal areas and their corresponding keywords or acts as needed\n",
    "        }\n",
    "\n",
    "        # Check if any legal area keywords are in the text\n",
    "        for area, pattern in legal_areas.items():\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                return area  # Return the first matched legal area\n",
    "\n",
    "        return \"General Law\"  # Default if no specific area is matched\n",
    "    features['Legal Area'] = extract_legal_area(text)\n",
    "    \n",
    "\n",
    "\n",
    "    def extract_core_legal_issues(text):\n",
    "        core_issues = {\n",
    "            \"Compensation\": r\"compensation|damages|reparation\",\n",
    "            \"Dependency\": r\"dependency|dependents|support\",\n",
    "            \"Negligence\": r\"negligence|carelessness|breach of duty\",\n",
    "            \"Liability\": r\"liability|responsibility|accountability\",\n",
    "            \"Family Pension\": r\"family pension|survivor benefits\",\n",
    "            \"Breach of Contract\": r\"breach of contract|contract violation\",\n",
    "            \"Property Rights\": r\"property rights|ownership|title dispute\",\n",
    "            \"Environmental Protection\": r\"environmental protection|pollution|conservation\",\n",
    "            \"Intellectual Property\": r\"intellectual property|patent|copyright|trademark\",\n",
    "            \"Employment Dispute\": r\"employment dispute|labor rights|unfair dismissal\",\n",
    "            \"Criminal Offense\": r\"criminal offense|crime|offense\",\n",
    "            \"Fraud\": r\"fraud|deception|misrepresentation\",\n",
    "            \"Defamation\": r\"defamation|slander|libel\",\n",
    "            \"Divorce\": r\"divorce|marital dissolution|separation\",\n",
    "            \"Child Custody\": r\"child custody|custodial rights|parental rights\",\n",
    "            \"Inheritance\": r\"inheritance|succession|estate\",\n",
    "            # Add more issues and keywords as needed\n",
    "        }\n",
    "\n",
    "        matched_issues = []\n",
    "\n",
    "        # Check if any core legal issue keywords are in the text\n",
    "        for issue, pattern in core_issues.items():\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                matched_issues.append(issue)\n",
    "\n",
    "        return matched_issues if matched_issues else [\"General Issue\"]\n",
    "    issues = extract_core_legal_issues(text)\n",
    "    features['Core Legal Issues'] = issues\n",
    "\n",
    "    \n",
    "    # 9. Cited Precedents\n",
    "    cited_cases = re.findall(r'\\b[A-Z][a-z]+\\s+v\\.\\s+[A-Z][a-z]+\\b', text)\n",
    "    features['Cited Precedents'] = cited_cases if cited_cases else []\n",
    "    \n",
    "    # 10. Paragraph Count\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    features['Paragraph Count'] = len(paragraphs)\n",
    "    \n",
    "    # 11. Word Count\n",
    "    features['Word Count'] = len(text.split())\n",
    "    \n",
    "    # 12. Language Complexity (average sentence length)\n",
    "    def process_text_in_chunks(text, chunk_size=100000):\n",
    "        sentences = []\n",
    "        for i in range(0, len(text), chunk_size):\n",
    "            chunk = text[i:i+chunk_size]\n",
    "            doc = nlp(chunk)\n",
    "            sentences.extend(list(doc.sents))  # Collect sentences from each chunk\n",
    "        return sentences\n",
    "\n",
    "    # Now use the function to get sentences and calculate the average sentence length\n",
    "    sentences = process_text_in_chunks(text)\n",
    "    avg_sentence_length = sum(len(sentence) for sentence in sentences) / len(sentences) if sentences else 0\n",
    "    features['Average Sentence Length'] = round(avg_sentence_length, 2)\n",
    "\n",
    "    # 13. Sentiment/Tone (for simplicity, labeling neutral here)\n",
    "    features['Sentiment/Tone'] = \"Neutral\"\n",
    "    \n",
    "    # 14. Judge(s) Authoring the Judgment\n",
    "    judges = re.findall(r'(?i)JUDGMENT\\s*+\\n?\\s*+([A-Za-z\\s]+),\\s*J\\.', text)\n",
    "\n",
    "    bench_match = re.search(r\"Bench:\\s*(.*?)\\n\", text)  # Search for the bench composition line\n",
    "\n",
    "    if bench_match:\n",
    "        # Strip whitespace and split by commas if there are multiple judges listed\n",
    "        additional_judges = [x.strip() for x in bench_match.group(1).strip().split(',')]\n",
    "        judges.extend(additional_judges)  # Use extend to add the list of judges\n",
    "\n",
    "    features['Judges'] = list(set(judges))  # Remove duplicates by converting to a set and back to a list\n",
    "\n",
    "    # 15. Bench Composition\n",
    "    features['Bench Composition'] = len(features['Judges'])\n",
    "    \n",
    "    # 16. Concurrence/Dissent Status\n",
    "    features['Concurrence/Dissent Status'] = \"Concurrence\" if \"concurrence\" in text.lower() else \"Unanimous\"\n",
    "    \n",
    "    # 17. Case Outcome\n",
    "    outcome_match = re.search(r'\\bappeals? (allowed|dismissed|partially allowed|granted)\\b', text, re.IGNORECASE)\n",
    "    if outcome_match:\n",
    "        features['Case Outcome'] = outcome_match.group().capitalize()\n",
    "    \n",
    "    # 18. Relief Granted (extract monetary figures)\n",
    "    relief_amounts = re.findall(r'Rs\\.\\s?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)\n",
    "    # Remove 'Rs.', commas, and convert each amount to an integer before summing\n",
    "    features['Relief Granted'] = sum(float(amount.replace('Rs.', '').replace(',', '').strip()) for amount in relief_amounts) if relief_amounts else 0\n",
    "\n",
    "    \n",
    "    # 19. Appeal Status\n",
    "    features['Appeal Status'] = \"Appellate Decision\" if \"appeal\" in text.lower() else \"Original Jurisdiction\"\n",
    "    \n",
    "    # 20. Number of Citations\n",
    "    features['Number of Citations'] = len(features['Cited Precedents'])\n",
    "    \n",
    "    # 21. Primary Statutes or Articles Cited\n",
    "    statutes = re.findall(r'\\b(?:Section|Article)\\s+\\d+\\b', text)\n",
    "    features['Primary Statutes'] = list(set(statutes))\n",
    "    features['Number of Primary Statutes'] = len(list(set(statutes)))\n",
    "    \n",
    "    \n",
    "    def get_court_abbreviation(text):\n",
    "        # Define abbreviations for different courts\n",
    "        court_abbreviations = {\n",
    "            \"Supreme Court of India\": \"SCI\",\n",
    "            \"Allahabad High Court\": \"AHC\",\n",
    "            \"Madhya Pradesh High Court\": \"MPHC\",\n",
    "        }\n",
    "\n",
    "        # Search for the court name in the text and return the corresponding abbreviation\n",
    "        for court, abbreviation in court_abbreviations.items():\n",
    "            if court in text:\n",
    "                return abbreviation\n",
    "\n",
    "        return \"UNK\"  # Default abbreviation if no court is found\n",
    "\n",
    "    features['case_id'] = f\"{get_court_abbreviation(text)}_{os.path.splitext(filename)[0]}\"\n",
    "\n",
    "    features['Number of Core Legal Issues'] = len(issues)\n",
    "    \n",
    "    return features\n",
    "# Function to process all text files in a folder and combine results into a single JSON file\n",
    "def process_folder(folder_path):\n",
    "    all_features = []  # List to store features from all documents\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Read text from file\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_features(text,filename)\n",
    "            all_features.append(features)  # Append features to the list\n",
    "            \n",
    "            print(f\"Processed: {filename}\")\n",
    "\n",
    "    # Save all extracted features to a single JSON file\n",
    "    combined_json_path = os.path.join(folder_path, \"combined_features.json\")\n",
    "    with open(combined_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(all_features, json_file, indent=4)\n",
    "\n",
    "    print(f\"All features saved to: {combined_json_path}\")\n",
    "\n",
    "# Folder path containing the .txt files\n",
    "folder_path = \"Yearwise_data/1950\"\n",
    "\n",
    "# Process all .txt files in the folder\n",
    "process_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evn1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
